{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying Amazon Reviews - New Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbIgryLL4Ytx",
        "outputId": "68fca15e-6201-40fc-b050-172a5321177b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import string\n",
        "import bz2\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRzJJsDX5bVZ",
        "outputId": "732a346b-8ae9-4cd0-cec7-cecdb1d36a66"
      },
      "source": [
        "# load files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoL7uCNh7Fw5",
        "outputId": "b638b335-9b32-4619-d106-f0274b251508"
      },
      "source": [
        "data = bz2.BZ2File(\"/content/drive/MyDrive/python homework/test.ft.txt.bz2\")\n",
        "data = data.readlines()\n",
        "print(\"Number of  reviews: \" + str(len(data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of  reviews: 400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bv_qGgZ8TVD",
        "outputId": "6aae30e8-4114-4b97-9459-9a6c16b67b8a"
      },
      "source": [
        "sample_size = 200000 #Using 200,000 reviews from test set\n",
        "data = [x.decode('utf-8') for x in data[:sample_size]]\n",
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcYiRoz--qGD"
      },
      "source": [
        "__label__2 is positive and __label__1 is negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JvhZFQr-K08"
      },
      "source": [
        "df = pd.DataFrame({'text':data})\n",
        "df['target'] = df.text.apply(lambda x: 1 if '__label__2' in x.split() else 0)\n",
        "# clean target from text\n",
        "df['text'] = df.text.apply(lambda x: re.sub(r'__label__\\d','',x).strip())\n",
        "# turn urls into a <url> token\n",
        "df['text'] = df.text.apply(lambda x: re.sub(r'([^ ]+(?<=\\.[a-z]{3}))', '<url>',x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE11kA6Z6t9Y",
        "outputId": "fc9a743b-aca9-4160-d537-7f9456147b20"
      },
      "source": [
        "# Too many positives so unbalanced dataset\n",
        "df.value_counts('target')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "1    100565\n",
              "0     99435\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-b_-gN7TUA"
      },
      "source": [
        "# Let's balance it by gettign as many positives as there are negatives\n",
        "df_negatives = df[df.target == 0]\n",
        "df_positives = df[df.target == 1].sample(df_negatives.shape[0], random_state = 1)\n",
        "df_balanced = pd.concat([df_negatives, df_positives])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8lPCVgI77M1",
        "outputId": "5621b9ff-9898-456e-fa21-ab8799e61496"
      },
      "source": [
        "df_balanced.value_counts('target')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "1    99435\n",
              "0    99435\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZmpS4Ep-NbQ"
      },
      "source": [
        "How are review text sizes distributed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "_VWQ3sDy-KHI",
        "outputId": "aa976e0e-777b-477f-df4d-acbdb07445bd"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.boxplot(df_balanced.text.apply(lambda x: len(x.split())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b124ccb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T50ow228Vco"
      },
      "source": [
        "Okay, now we are ready to pre-process this text so that we can use it in our LSTM network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97e4_rxj8Ra_"
      },
      "source": [
        "STOP_WORDS = set(stopwords.words('english')) \n",
        "\n",
        "# TODO improve with more filters\n",
        "def preprocess_text(raw_text):\n",
        "      global STOP_WORDS\n",
        "      word_list = []\n",
        "      for word in raw_text.lower().strip().split():\n",
        "            word = re.sub(r'\\d', '', word) # removes digits\n",
        "            word = re.sub(r\"[^\\w\\s]\", '', word) # removes all non word chars\n",
        "            if word not in STOP_WORDS and word != '':\n",
        "                word_list.append(word)\n",
        "\n",
        "      return ' '.join(word_list)\n",
        "\n",
        "df_balanced['cleaned_text'] = df_balanced.text.apply(lambda x: preprocess_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2l4RXpAY9woQ",
        "outputId": "88293a55-d515-4ae3-e856-e9207eddbb71"
      },
      "source": [
        "df_balanced.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Batteries died within a year ...: I bought thi...</td>\n",
              "      <td>0</td>\n",
              "      <td>batteries died within year bought charger jul ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DVD Player crapped out after one year: I also ...</td>\n",
              "      <td>0</td>\n",
              "      <td>dvd player crapped one year also began incorre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Incorrect Disc: I love the style of this, but ...</td>\n",
              "      <td>0</td>\n",
              "      <td>incorrect disc love style couple years dvd giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DVD menu select problems: I cannot scroll thro...</td>\n",
              "      <td>0</td>\n",
              "      <td>dvd menu select problems cannot scroll dvd men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Not an \"ultimate guide\": Firstly,I enjoyed the...</td>\n",
              "      <td>0</td>\n",
              "      <td>ultimate guide firstlyi enjoyed format tone bo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                       cleaned_text\n",
              "2  Batteries died within a year ...: I bought thi...  ...  batteries died within year bought charger jul ...\n",
              "5  DVD Player crapped out after one year: I also ...  ...  dvd player crapped one year also began incorre...\n",
              "6  Incorrect Disc: I love the style of this, but ...  ...  incorrect disc love style couple years dvd giv...\n",
              "7  DVD menu select problems: I cannot scroll thro...  ...  dvd menu select problems cannot scroll dvd men...\n",
              "9  Not an \"ultimate guide\": Firstly,I enjoyed the...  ...  ultimate guide firstlyi enjoyed format tone bo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQBzWkQ-40x"
      },
      "source": [
        "We check distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "YgFQ9e2e95fn",
        "outputId": "547f2140-e3d9-40f0-df06-b65db0d2741f"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.boxplot(df_balanced.cleaned_text.apply(lambda x: len(x.split())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b125077d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elZFLiSl-pr3",
        "outputId": "ecde2f12-c8fa-41bb-c89f-6ade2ee43ddc"
      },
      "source": [
        "df_balanced.cleaned_text.apply(lambda x: len(x.split())).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    198870.000000\n",
              "mean         40.472972\n",
              "std          21.956238\n",
              "min           4.000000\n",
              "25%          22.000000\n",
              "50%          36.000000\n",
              "75%          55.000000\n",
              "max         157.000000\n",
              "Name: cleaned_text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FTKCL8Z-744"
      },
      "source": [
        "Now that we already have the cleaned text we can go ahead and create a dictionary, so that we can use words as numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6XweqdFAEgf"
      },
      "source": [
        "all_words = [ w for s in df_balanced.cleaned_text.values.tolist() for w in s.split()]\n",
        "words = Counter(all_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9ECPbmBZWI"
      },
      "source": [
        "There seems to be many positive words, maybe classifier learn by lack of positive words or by a couple negative but at first glance it looks challenging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S4xhni1_-0P",
        "outputId": "326158bb-07a7-4362-bfcd-d7eca8f953a7"
      },
      "source": [
        "words.most_common(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('book', 107613),\n",
              " ('one', 74654),\n",
              " ('like', 58147),\n",
              " ('great', 57939),\n",
              " ('good', 56904),\n",
              " ('would', 45172),\n",
              " ('movie', 42563),\n",
              " ('read', 40128),\n",
              " ('get', 37120),\n",
              " ('time', 36364),\n",
              " ('dont', 34892),\n",
              " ('really', 32485),\n",
              " ('first', 28232),\n",
              " ('even', 27980),\n",
              " ('much', 27850),\n",
              " ('well', 27684),\n",
              " ('love', 26349),\n",
              " ('best', 24150),\n",
              " ('album', 23528),\n",
              " ('buy', 23493),\n",
              " ('cd', 23301),\n",
              " ('better', 22642),\n",
              " ('story', 21102),\n",
              " ('product', 21044),\n",
              " ('could', 20568),\n",
              " ('work', 20135),\n",
              " ('also', 20049),\n",
              " ('use', 20038),\n",
              " ('new', 19375),\n",
              " ('way', 19171)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JySXi1tnAAOv"
      },
      "source": [
        "words = {k:v for k,v in words.items() if v > 1}\n",
        "# Sorting on the basis of most common words\n",
        "words = sorted(words, key = words.get, reverse = True)\n",
        "words = ['_PAD', '_UNK'] + words\n",
        "\n",
        "# Creating a dict\n",
        "word_to_idx = { w : i for i,w in enumerate(words) }\n",
        "idx_to_word = {v : k for k,v in word_to_idx.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u0T_J6fCQk0"
      },
      "source": [
        "def process_sequence(text_sequence):\n",
        "  global word_to_idx\n",
        "  res = []\n",
        "  for w in text_sequence:\n",
        "    if w in word_to_idx:\n",
        "      res.append(word_to_idx[w])\n",
        "    else:\n",
        "      res.append(1)\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hijb5ydPC1ug"
      },
      "source": [
        "We are ready to created the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyW0BaTfCRKO"
      },
      "source": [
        "X = [process_sequence(s.split()) for s in df_balanced.cleaned_text.values.tolist()]\n",
        "y = df_balanced.target.values.tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCFTX7VyDPGP"
      },
      "source": [
        "# we get the longest sequences for train and we use this to pad both train and test\n",
        "MAX_LEN = max([len(s) for s in  X_train])\n",
        "\n",
        "\n",
        "'''\n",
        "*What I learned:*\n",
        "Commonly in RNN's, we take the final output or hidden state and use this to make a prediction (or do whatever task we are trying to do).\n",
        "If we send a bunch of 0's to the RNN before taking the final output (i.e. 'post' padding as you describe), \n",
        "then the hidden state of the network at the final word in the sentence would likely get 'flushed out' to some extent by all the zero inputs that come after this word.\n",
        "So intuitively, this might be why pre-padding is more popular/effective.\n",
        "'''\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen = MAX_LEN, padding = 'pre')\n",
        "X_test = pad_sequences(X_test, maxlen = MAX_LEN, padding = 'pre')\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUQW8DiyLct9"
      },
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uqJbO6VMRf9"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size, drop_last = True)\n",
        "test_loader = DataLoader(test_data, shuffle = True, batch_size = batch_size, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIQEpBUFpen"
      },
      "source": [
        "So now we can go ahead and create and use our model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHav29mcFbC2"
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob = 0.5):\n",
        "        super(SentimentLSTM, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first = True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size) # fully connected\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long() # cast to long tensor\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "        \n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-1]\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VVMur4DKyBd",
        "outputId": "04cb166c-0b81-45e2-b3fd-19dac46e37df"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVQKGp3fKX4a",
        "outputId": "82ad5a9a-f62f-464e-8ef4-bba0ed89a641"
      },
      "source": [
        "vocab_size = len(word_to_idx) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400 # TODO: try 128 or 256\n",
        "hidden_dim = 512 # TODO: try 256\n",
        "n_layers = 2\n",
        "\n",
        "model = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(98123, 400)\n",
            "  (lstm): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2busAtQK1Z1"
      },
      "source": [
        "lr = 0.005\n",
        "criterion = nn.BCELoss() # binary cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKjCRXJKLKaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533c3073-8c96-4a0a-c6a9-2a204ba9f271"
      },
      "source": [
        "epochs = 2\n",
        "counter = 0\n",
        "print_every = 50\n",
        "clip = 5\n",
        "test_loss_min = np.Inf\n",
        "\n",
        "model.train() # model set to training mode\n",
        "\n",
        "for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        h = tuple([e.data for e in h])\n",
        "        model.zero_grad() # reset gradients \n",
        "        output, h = model(inputs, h) # forward propagation\n",
        "        loss = criterion(output.squeeze(), labels.float()) # compute loss\n",
        "        loss.backward() # backward propagation\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip) # regularization by clipping gradient\n",
        "        optimizer.step() # apply gradients\n",
        "        \n",
        "        # METRICS:\n",
        "        if counter%print_every == 0:\n",
        "            test_h = model.init_hidden(batch_size)\n",
        "            test_losses = []\n",
        "            num_correct = 0\n",
        "            model.eval()\n",
        "            for inp, lab in test_loader:\n",
        "                test_h = tuple([each.data for each in test_h])\n",
        "                inp, lab = inp.to(device), lab.to(device)\n",
        "                out, test_h = model(inp, test_h)\n",
        "                test_loss = criterion(out.squeeze(), lab.float())\n",
        "                test_losses.append(test_loss.item())\n",
        "\n",
        "                # Compute acc\n",
        "                pred = torch.round(out.squeeze()) #rounds the output to 0/1\n",
        "                correct_tensor = pred.eq(lab.float().view_as(pred)) # calculate how many preds == labels\n",
        "                correct = np.squeeze(correct_tensor.cpu().numpy()) # like np.ravel\n",
        "                num_correct += np.sum(correct) # sums matches\n",
        "\n",
        "            print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "            test_acc = num_correct/len(test_loader.dataset)\n",
        "            print(\"Test accuracy: {:.3f}%\".format(test_acc*100))\n",
        "\n",
        "                \n",
        "            model.train()\n",
        "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Test Loss: {:.6f}\".format(np.mean(test_losses)))\n",
        "            if np.mean(test_losses) <= test_loss_min:\n",
        "                torch.save(model.state_dict(), '/content/drive/MyDrive/python homework/best_LSTM_model.pt')\n",
        "                print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min, np.mean(test_losses)))\n",
        "                test_loss_min = np.mean(test_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.433\n",
            "Test accuracy: 81.447%\n",
            "Epoch: 1/2... Step: 50... Loss: 0.457428... Test Loss: 0.432603\n",
            "Test loss decreased (inf --> 0.432603).  Saving model ...\n",
            "Test loss: 0.326\n",
            "Test accuracy: 85.846%\n",
            "Epoch: 1/2... Step: 100... Loss: 0.327979... Test Loss: 0.326463\n",
            "Test loss decreased (0.432603 --> 0.326463).  Saving model ...\n",
            "Test loss: 0.295\n",
            "Test accuracy: 87.542%\n",
            "Epoch: 1/2... Step: 150... Loss: 0.312631... Test Loss: 0.295326\n",
            "Test loss decreased (0.326463 --> 0.295326).  Saving model ...\n",
            "Test loss: 0.289\n",
            "Test accuracy: 88.109%\n",
            "Epoch: 1/2... Step: 200... Loss: 0.282673... Test Loss: 0.288972\n",
            "Test loss decreased (0.295326 --> 0.288972).  Saving model ...\n",
            "Test loss: 0.270\n",
            "Test accuracy: 88.819%\n",
            "Epoch: 1/2... Step: 250... Loss: 0.263437... Test Loss: 0.270251\n",
            "Test loss decreased (0.288972 --> 0.270251).  Saving model ...\n",
            "Test loss: 0.269\n",
            "Test accuracy: 89.155%\n",
            "Epoch: 2/2... Step: 300... Loss: 0.218855... Test Loss: 0.268633\n",
            "Test loss decreased (0.270251 --> 0.268633).  Saving model ...\n",
            "Test loss: 0.269\n",
            "Test accuracy: 89.119%\n",
            "Epoch: 2/2... Step: 350... Loss: 0.167450... Test Loss: 0.269054\n",
            "Test loss: 0.268\n",
            "Test accuracy: 88.517%\n",
            "Epoch: 2/2... Step: 400... Loss: 0.184127... Test Loss: 0.267530\n",
            "Test loss decreased (0.268633 --> 0.267530).  Saving model ...\n",
            "Test loss: 0.271\n",
            "Test accuracy: 89.185%\n",
            "Epoch: 2/2... Step: 450... Loss: 0.257430... Test Loss: 0.270628\n",
            "Test loss: 0.266\n",
            "Test accuracy: 89.368%\n",
            "Epoch: 2/2... Step: 500... Loss: 0.179317... Test Loss: 0.266439\n",
            "Test loss decreased (0.267530 --> 0.266439).  Saving model ...\n",
            "Test loss: 0.257\n",
            "Test accuracy: 89.517%\n",
            "Epoch: 2/2... Step: 550... Loss: 0.227016... Test Loss: 0.256734\n",
            "Test loss decreased (0.266439 --> 0.256734).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Lfy7SRRP0p",
        "outputId": "b27790d6-0edb-468c-8c44-30de6c570318"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/python homework/best_LSTM_model.pt'))\n",
        "model.eval()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(98123, 400)\n",
            "  (lstm): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuq7TWtKCk1C"
      },
      "source": [
        "def process_custom(text):\n",
        "  global MAX_LEN\n",
        "  sequence = process_sequence(text.split())\n",
        "  # quick pre-padding\n",
        "  sequence = [0]*(MAX_LEN - len(sequence)) + sequence\n",
        "  return torch.unsqueeze(torch.from_numpy(np.array(sequence)), 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQB18paLLZf7"
      },
      "source": [
        "negative_review = 'This product is the worst! I would not recommend buying it at all. A fucking mess.'\n",
        "positive_review = 'The product is of good quality overall. However, some things could be improved. But it is a nice buy.'\n",
        "neutral_review = 'The latest marvel comic was not as good as I expected, however this movie ended up being much better than I thought. You should give it a try.'\n",
        "\n",
        "custom_review_tensor = process_custom(negative_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi5-W44bM7SO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c0667c-dda4-4b61-d442-087dc2ebfb07"
      },
      "source": [
        "test_h = model.init_hidden(1)\n",
        "out, test_h = model(custom_review_tensor.to(device), test_h)\n",
        "torch.round(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], device='cuda:0', grad_fn=<RoundBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbqPCIt6ROcn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}