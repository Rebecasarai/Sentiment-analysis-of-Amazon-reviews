{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying_Amazon_Reviews_New_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpG4fBVjY1hN"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbIgryLL4Ytx",
        "outputId": "960bb422-a1f3-427d-bdc4-d31faf05ca7c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import string\n",
        "import bz2\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRzJJsDX5bVZ",
        "outputId": "6b3eeec5-112f-40c1-9fa0-62fd87487138"
      },
      "source": [
        "# load files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoL7uCNh7Fw5",
        "outputId": "b9735235-7da7-42be-dcf0-d303683303f4"
      },
      "source": [
        "data = bz2.BZ2File(\"/content/drive/MyDrive/python homework/test.ft.txt.bz2\")\n",
        "data = data.readlines()\n",
        "print(\"Number of  reviews: \" + str(len(data)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of  reviews: 400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bv_qGgZ8TVD",
        "outputId": "f6d48929-6971-429e-ac4e-cb28ecf895e3"
      },
      "source": [
        "sample_size = 200000 #Using 200,000 reviews from test set\n",
        "data = [x.decode('utf-8') for x in data[:sample_size]]\n",
        "print(data[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMUab-WcY7J_"
      },
      "source": [
        "# Exploring and processing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRxdf9QuZXpT"
      },
      "source": [
        "## Cleaning the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcYiRoz--qGD"
      },
      "source": [
        "__label__2 is positive and __label__1 is negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JvhZFQr-K08"
      },
      "source": [
        "df = pd.DataFrame({'text':data})\n",
        "df['target'] = df.text.apply(lambda x: 1 if '__label__2' in x.split() else 0)\n",
        "# clean target from text\n",
        "df['text'] = df.text.apply(lambda x: re.sub(r'__label__\\d','',x).strip())\n",
        "# turn urls into a <url> token\n",
        "df['text'] = df.text.apply(lambda x: re.sub(r'([^ ]+(?<=\\.[a-z]{3}))', '<url>',x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE11kA6Z6t9Y",
        "outputId": "8cfec8b4-e9a8-45c8-a155-ef5ab941ca79"
      },
      "source": [
        "# Too many positives so unbalanced dataset\n",
        "df.value_counts('target')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "1    100565\n",
              "0     99435\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-b_-gN7TUA"
      },
      "source": [
        "# Let's balance it by gettign as many positives as there are negatives\n",
        "df_negatives = df[df.target == 0]\n",
        "df_positives = df[df.target == 1].sample(df_negatives.shape[0], random_state = 1)\n",
        "df_balanced = pd.concat([df_negatives, df_positives])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8lPCVgI77M1",
        "outputId": "78fb8dae-4937-464c-b3df-f55e89e5cd4b"
      },
      "source": [
        "df_balanced.value_counts('target')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "1    99435\n",
              "0    99435\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZmpS4Ep-NbQ"
      },
      "source": [
        "## How are review text sizes distributed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "_VWQ3sDy-KHI",
        "outputId": "a147eb00-85d7-4c88-d294-7fe21bc98d89"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.boxplot(df_balanced.text.apply(lambda x: len(x.split())))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f47f5a78e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T50ow228Vco"
      },
      "source": [
        "Okay, now we are ready to pre-process this text so that we can use it in our LSTM network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97e4_rxj8Ra_"
      },
      "source": [
        "STOP_WORDS = set(stopwords.words('english')) \n",
        "\n",
        "# TODO improve with more filters\n",
        "def preprocess_text(raw_text):\n",
        "      global STOP_WORDS\n",
        "      word_list = []\n",
        "      for word in raw_text.lower().strip().split():\n",
        "            word = re.sub(r'\\d', '', word) # removes digits\n",
        "            word = re.sub(r\"[^\\w\\s]\", '', word) # removes all non word chars\n",
        "            if word not in STOP_WORDS and word != '':\n",
        "                word_list.append(word)\n",
        "\n",
        "      return ' '.join(word_list)\n",
        "\n",
        "df_balanced['cleaned_text'] = df_balanced.text.apply(lambda x: preprocess_text(x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "2l4RXpAY9woQ",
        "outputId": "40431ed6-bb61-4cf7-d780-065d6acb3aa2"
      },
      "source": [
        "df_balanced.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Batteries died within a year ...: I bought thi...</td>\n",
              "      <td>0</td>\n",
              "      <td>batteries died within year bought charger jul ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DVD Player crapped out after one year: I also ...</td>\n",
              "      <td>0</td>\n",
              "      <td>dvd player crapped one year also began incorre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Incorrect Disc: I love the style of this, but ...</td>\n",
              "      <td>0</td>\n",
              "      <td>incorrect disc love style couple years dvd giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DVD menu select problems: I cannot scroll thro...</td>\n",
              "      <td>0</td>\n",
              "      <td>dvd menu select problems cannot scroll dvd men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Not an \"ultimate guide\": Firstly,I enjoyed the...</td>\n",
              "      <td>0</td>\n",
              "      <td>ultimate guide firstlyi enjoyed format tone bo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                       cleaned_text\n",
              "2  Batteries died within a year ...: I bought thi...  ...  batteries died within year bought charger jul ...\n",
              "5  DVD Player crapped out after one year: I also ...  ...  dvd player crapped one year also began incorre...\n",
              "6  Incorrect Disc: I love the style of this, but ...  ...  incorrect disc love style couple years dvd giv...\n",
              "7  DVD menu select problems: I cannot scroll thro...  ...  dvd menu select problems cannot scroll dvd men...\n",
              "9  Not an \"ultimate guide\": Firstly,I enjoyed the...  ...  ultimate guide firstlyi enjoyed format tone bo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQBzWkQ-40x"
      },
      "source": [
        "We check distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "YgFQ9e2e95fn",
        "outputId": "63de7911-1ecf-4cc3-c009-6a451e156ee6"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.boxplot(df_balanced.cleaned_text.apply(lambda x: len(x.split())))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f47f9f9ebd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elZFLiSl-pr3",
        "outputId": "cb96dbcd-a81d-4a6e-d1af-3f825be07984"
      },
      "source": [
        "df_balanced.cleaned_text.apply(lambda x: len(x.split())).describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    198870.000000\n",
              "mean         40.472972\n",
              "std          21.956238\n",
              "min           4.000000\n",
              "25%          22.000000\n",
              "50%          36.000000\n",
              "75%          55.000000\n",
              "max         157.000000\n",
              "Name: cleaned_text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMZ_BYyKZNC5"
      },
      "source": [
        "## Creating vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FTKCL8Z-744"
      },
      "source": [
        "Now that we already have the cleaned text we can go ahead and create a dictionary, so that we can use words as numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6XweqdFAEgf"
      },
      "source": [
        "all_words = [ w for s in df_balanced.cleaned_text.values.tolist() for w in s.split()]\n",
        "words = Counter(all_words)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9ECPbmBZWI"
      },
      "source": [
        "There seems to be many positive words, maybe classifier learn by lack of positive words or by a couple negative but at first glance it looks challenging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S4xhni1_-0P",
        "outputId": "5511abe9-b413-4d09-e906-55e37c70d200"
      },
      "source": [
        "words.most_common(30)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('book', 107613),\n",
              " ('one', 74654),\n",
              " ('like', 58147),\n",
              " ('great', 57939),\n",
              " ('good', 56904),\n",
              " ('would', 45172),\n",
              " ('movie', 42563),\n",
              " ('read', 40128),\n",
              " ('get', 37120),\n",
              " ('time', 36364),\n",
              " ('dont', 34892),\n",
              " ('really', 32485),\n",
              " ('first', 28232),\n",
              " ('even', 27980),\n",
              " ('much', 27850),\n",
              " ('well', 27684),\n",
              " ('love', 26349),\n",
              " ('best', 24150),\n",
              " ('album', 23528),\n",
              " ('buy', 23493),\n",
              " ('cd', 23301),\n",
              " ('better', 22642),\n",
              " ('story', 21102),\n",
              " ('product', 21044),\n",
              " ('could', 20568),\n",
              " ('work', 20135),\n",
              " ('also', 20049),\n",
              " ('use', 20038),\n",
              " ('new', 19375),\n",
              " ('way', 19171)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JySXi1tnAAOv"
      },
      "source": [
        "words = {k:v for k,v in words.items() if v > 1}\n",
        "# Sorting on the basis of most common words\n",
        "words = sorted(words, key = words.get, reverse = True)\n",
        "words = ['_PAD', '_UNK'] + words\n",
        "\n",
        "# Creating a dict\n",
        "word_to_idx = { w : i for i,w in enumerate(words) }\n",
        "idx_to_word = {v : k for k,v in word_to_idx.items()}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u0T_J6fCQk0"
      },
      "source": [
        "def process_sequence(text_sequence):\n",
        "  global word_to_idx\n",
        "  res = []\n",
        "  for w in text_sequence:\n",
        "    if w in word_to_idx:\n",
        "      res.append(word_to_idx[w])\n",
        "    else:\n",
        "      res.append(1)\n",
        "  return res"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbQ562ieZi3M"
      },
      "source": [
        "# Adding padding (Important note)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hijb5ydPC1ug"
      },
      "source": [
        "We are ready to created the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyW0BaTfCRKO"
      },
      "source": [
        "X = [process_sequence(s.split()) for s in df_balanced.cleaned_text.values.tolist()]\n",
        "y = df_balanced.target.values.tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCFTX7VyDPGP"
      },
      "source": [
        "# we get the longest sequences for train and we use this to pad both train and test\n",
        "MAX_LEN = max([len(s) for s in  X_train])\n",
        "\n",
        "\n",
        "'''\n",
        "*What I learned:*\n",
        "Commonly in RNN's, we take the final output or hidden state and use this to make a prediction (or do whatever task we are trying to do).\n",
        "If we send a bunch of 0's to the RNN before taking the final output (i.e. 'post' padding as you describe), \n",
        "then the hidden state of the network at the final word in the sentence would likely get 'flushed out' to some extent by all the zero inputs that come after this word.\n",
        "So intuitively, this might be why pre-padding is more popular/effective.\n",
        "'''\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen = MAX_LEN, padding = 'pre')\n",
        "X_test = pad_sequences(X_test, maxlen = MAX_LEN, padding = 'pre')\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUQW8DiyLct9"
      },
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uqJbO6VMRf9"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size, drop_last = True)\n",
        "test_loader = DataLoader(test_data, shuffle = True, batch_size = batch_size, drop_last = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fzkZp6nZ6iP"
      },
      "source": [
        "# The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIQEpBUFpen"
      },
      "source": [
        "So now we can go ahead and create and use our model!\n",
        "\n",
        "We use some hyperparameters such as the vocab size, the hidden layer dimension, the number of layers and the dropout probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHav29mcFbC2"
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob = 0.5):\n",
        "        super(SentimentLSTM, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first = True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size) # fully connected\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long() # cast to long tensor\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "        \n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-1]\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return hidden"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VVMur4DKyBd",
        "outputId": "17cf8f50-0dbe-4a79-8d74-b1a0dedd925e"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVQKGp3fKX4a",
        "outputId": "632f5435-4d79-4566-baf6-ee45ce537f0c"
      },
      "source": [
        "vocab_size = len(word_to_idx) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400 # TODO: try 128 or 256\n",
        "hidden_dim = 512 # TODO: try 256\n",
        "n_layers = 2\n",
        "\n",
        "model = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(98123, 400)\n",
            "  (lstm): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2busAtQK1Z1"
      },
      "source": [
        "lr = 0.005\n",
        "criterion = nn.BCELoss() # binary cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO4X720FaA8f"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "We save the best model based on the loss function, mean ing that it will take as the best model the one with the smallest value of test_losses. \n",
        "\n",
        "That could also mean that the best model might not have the highest accuracy score, although the difference is small.\n",
        "\n",
        "It will save the model as \"best_LSTM_model.pt\" in ghe shared drive folder.\n",
        "\n",
        "We reach 89% of accuracy with 2 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKjCRXJKLKaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9438f2ea-c7a1-44eb-c8ff-761e4622fff8"
      },
      "source": [
        "epochs = 2\n",
        "counter = 0\n",
        "print_every = 50\n",
        "clip = 5\n",
        "test_loss_min = np.Inf\n",
        "\n",
        "model.train() # model set to training mode\n",
        "\n",
        "for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        h = tuple([e.data for e in h])\n",
        "        model.zero_grad() # reset gradients \n",
        "        output, h = model(inputs, h) # forward propagation\n",
        "        loss = criterion(output.squeeze(), labels.float()) # compute loss\n",
        "        loss.backward() # backward propagation\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip) # regularization by clipping gradient\n",
        "        optimizer.step() # apply gradients\n",
        "        \n",
        "        # METRICS:\n",
        "        if counter%print_every == 0:\n",
        "            test_h = model.init_hidden(batch_size)\n",
        "            test_losses = []\n",
        "            num_correct = 0\n",
        "            model.eval()\n",
        "            for inp, lab in test_loader:\n",
        "                test_h = tuple([each.data for each in test_h])\n",
        "                inp, lab = inp.to(device), lab.to(device)\n",
        "                out, test_h = model(inp, test_h)\n",
        "                test_loss = criterion(out.squeeze(), lab.float())\n",
        "                test_losses.append(test_loss.item())\n",
        "\n",
        "                # Compute acc\n",
        "                pred = torch.round(out.squeeze()) #rounds the output to 0/1\n",
        "                correct_tensor = pred.eq(lab.float().view_as(pred)) # calculate how many preds == labels\n",
        "                correct = np.squeeze(correct_tensor.cpu().numpy()) # like np.ravel\n",
        "                num_correct += np.sum(correct) # sums matches\n",
        "\n",
        "            print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "            test_acc = num_correct/len(test_loader.dataset)\n",
        "            print(\"Test accuracy: {:.3f}%\".format(test_acc*100))\n",
        "\n",
        "                \n",
        "            model.train()\n",
        "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Test Loss: {:.6f}\".format(np.mean(test_losses)))\n",
        "            if np.mean(test_losses) <= test_loss_min:\n",
        "                torch.save(model.state_dict(), '/content/drive/MyDrive/python homework/best_LSTM_model.pt')\n",
        "                print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min, np.mean(test_losses)))\n",
        "                test_loss_min = np.mean(test_losses)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.499\n",
            "Test accuracy: 76.447%\n",
            "Epoch: 1/2... Step: 50... Loss: 0.512610... Test Loss: 0.498585\n",
            "Test loss decreased (inf --> 0.498585).  Saving model ...\n",
            "Test loss: 0.419\n",
            "Test accuracy: 80.949%\n",
            "Epoch: 1/2... Step: 100... Loss: 0.382089... Test Loss: 0.419145\n",
            "Test loss decreased (0.498585 --> 0.419145).  Saving model ...\n",
            "Test loss: 0.320\n",
            "Test accuracy: 86.057%\n",
            "Epoch: 1/2... Step: 150... Loss: 0.300209... Test Loss: 0.320099\n",
            "Test loss decreased (0.419145 --> 0.320099).  Saving model ...\n",
            "Test loss: 0.296\n",
            "Test accuracy: 87.731%\n",
            "Epoch: 1/2... Step: 200... Loss: 0.296457... Test Loss: 0.296340\n",
            "Test loss decreased (0.320099 --> 0.296340).  Saving model ...\n",
            "Test loss: 0.275\n",
            "Test accuracy: 88.672%\n",
            "Epoch: 1/2... Step: 250... Loss: 0.301570... Test Loss: 0.275069\n",
            "Test loss decreased (0.296340 --> 0.275069).  Saving model ...\n",
            "Test loss: 0.274\n",
            "Test accuracy: 89.040%\n",
            "Epoch: 2/2... Step: 300... Loss: 0.200748... Test Loss: 0.274281\n",
            "Test loss decreased (0.275069 --> 0.274281).  Saving model ...\n",
            "Test loss: 0.268\n",
            "Test accuracy: 88.911%\n",
            "Epoch: 2/2... Step: 350... Loss: 0.184745... Test Loss: 0.268247\n",
            "Test loss decreased (0.274281 --> 0.268247).  Saving model ...\n",
            "Test loss: 0.278\n",
            "Test accuracy: 88.982%\n",
            "Epoch: 2/2... Step: 400... Loss: 0.239957... Test Loss: 0.277966\n",
            "Test loss: 0.266\n",
            "Test accuracy: 89.151%\n",
            "Epoch: 2/2... Step: 450... Loss: 0.247507... Test Loss: 0.266201\n",
            "Test loss decreased (0.268247 --> 0.266201).  Saving model ...\n",
            "Test loss: 0.266\n",
            "Test accuracy: 89.292%\n",
            "Epoch: 2/2... Step: 500... Loss: 0.193169... Test Loss: 0.266251\n",
            "Test loss: 0.256\n",
            "Test accuracy: 89.515%\n",
            "Epoch: 2/2... Step: 550... Loss: 0.246175... Test Loss: 0.256127\n",
            "Test loss decreased (0.266201 --> 0.256127).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sbsnpSgbBjj"
      },
      "source": [
        "# Testing the model and loading it from Drive\n",
        "\n",
        "we can load the best LSTM model previously trained and saved. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Lfy7SRRP0p",
        "outputId": "0a5148aa-fd42-48f9-a3cf-6a8b35d2a36c"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/python homework/best_LSTM_model.pt'))\n",
        "model.eval()\n",
        "print(model)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(98123, 400)\n",
            "  (lstm): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuq7TWtKCk1C"
      },
      "source": [
        "def process_custom(text):\n",
        "  global MAX_LEN\n",
        "  sequence = process_sequence(text.split())\n",
        "  # quick pre-padding\n",
        "  sequence = [0]*(MAX_LEN - len(sequence)) + sequence\n",
        "  return torch.unsqueeze(torch.from_numpy(np.array(sequence)), 0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw81g4M6VokI"
      },
      "source": [
        "def make_prediction(review, show_tensfor_shape=False):\n",
        "\n",
        "  label_dict={0:\"negative\", 1:\"positive\"}\n",
        "\n",
        "  custom_review_tensor = process_custom(review)\n",
        "  test_h = model.init_hidden(1)\n",
        "  out, test_h = model(custom_review_tensor.to(device), test_h)\n",
        "\n",
        "  if show_tensfor_shape == True:\n",
        "    print(custom_review_tensor)\n",
        "  \n",
        "  rounded_pred = torch.round(out)\n",
        "\n",
        "  print(\"Exact calculation:\", out)\n",
        "  print(\"\\nPrediction: {}. Representing a {} review.\".format(int(rounded_pred), label_dict[int(rounded_pred)]))\n",
        "  #return rounded_pred"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20nTsJMfbNs5"
      },
      "source": [
        "## Testing multiple types of reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJWZuQNwbXe9"
      },
      "source": [
        "### Negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQB18paLLZf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2760340-6fb4-4e66-969c-7f3117217ecc"
      },
      "source": [
        "negative_review = 'This product is the worst! I would not recommend buying it at all. A fucking mess.'\n",
        "\n",
        "make_prediction(negative_review)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exact calculation: tensor([0.1534], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "\n",
            "Prediction: 0. Representing a negative review.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mgDF3mmbTD6"
      },
      "source": [
        "### Positive rewiews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbqPCIt6ROcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f720cf5f-3eb4-45c5-9136-23560c57afe5"
      },
      "source": [
        "positive_review = 'The product is of good quality overall. However, some things could be improved. But it is a nice buy.'\n",
        "\n",
        "# Showing the encoded, padded review as a tensor. \"0\" represents PADDING.\n",
        "make_prediction(positive_review, True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  25,\n",
            "           1,   1,   6,  63,   1,   1,   1, 139,  26,   1,   1,   1,   1,   1,\n",
            "           1, 105,   1]])\n",
            "Exact calculation: tensor([0.8077], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "\n",
            "Prediction: 1. Representing a positive review.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t1azXHMYxfH"
      },
      "source": [
        "### Similar to neutral or confusing reviews\n",
        "If we test with more confusing or neutral reviews we can see how the model is able to middle out the calculated prediction to around 0.5 (In the middle between positive and negative)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRTRzjE3YH-j",
        "outputId": "32976a32-1c67-4da3-c4b3-aad5212347dc"
      },
      "source": [
        "neutral_review = 'The latest marvel comic was not as good as I expected, however this movie ended up being much better than I thought. You should give it a try.'\n",
        "\n",
        "# See that the calculated prediction is around 0.45 and 0.5\n",
        "make_prediction(neutral_review)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exact calculation: tensor([0.4668], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "\n",
            "Prediction: 0. Representing a negative review.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x35iadK6cI_c"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVDHWpErd8M-",
        "outputId": "b0434b86-a79f-4cdc-b90b-de8c0b95716a"
      },
      "source": [
        "# The data as pytorch tensors, including the reviews and the labels\n",
        "print(test_data.tensors)\n",
        "\n",
        "# Only the labels \n",
        "print(\"\\n\\nOnly the labels:\", test_data.tensors[1])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[    0,     0,     0,  ...,    66,  1009,  1247],\n",
            "        [    0,     0,     0,  ...,   436,     6,     3],\n",
            "        [    0,     0,     0,  ...,  3225,   182,    58],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,    74,   129,   452],\n",
            "        [    0,     0,     0,  ..., 21885, 27547,  2507],\n",
            "        [    0,     0,     0,  ...,   155,   660,    77]], dtype=torch.int32), tensor([1, 1, 1,  ..., 0, 0, 0]))\n",
            "\n",
            "\n",
            "Only the labels: tensor([1, 1, 1,  ..., 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4N_ei-diRrF",
        "outputId": "dded0772-9b47-4126-ced3-ec19949f69e9"
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "h = model.init_hidden(batch_size)\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "model.eval()\n",
        "for inputs, labels in test_loader:\n",
        "    h = tuple([each.data for each in h])\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    output, h = model(inputs, h)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    pred = torch.round(output.squeeze()) #rounds the output to 0/1\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "    y_pred.extend(pred.tolist())\n",
        "    y_true.extend(labels.tolist())\n",
        "        \n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.256\n",
            "Test accuracy: 89.515%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEevc_4Ejnar",
        "outputId": "0b9b51c5-9f30-4973-ebdc-0a4190fb7692"
      },
      "source": [
        "print(len(y_true), len(y_pred))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49664 49664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1SuXCUHlimT",
        "outputId": "f095bb69-74e3-431c-bd10-676b77db48d1"
      },
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(type(cm))\n",
        "cm"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22227,  2739],\n",
              "       [ 2420, 22278]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "9EArL5D1mAsV",
        "outputId": "06b7892f-477f-4ba6-f0bb-5cda2d2b8d2d"
      },
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')\n",
        "\n",
        "ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
        "ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
        "\n",
        "print()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP278q9roOas"
      },
      "source": [
        "# Evaluation\n",
        "We will use the F1-score evaluation method using scikit learn, as well as calculating it manually as we learned in the labs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QihzvQwmodg6"
      },
      "source": [
        "## Scikit-learn classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_bVVNqJmldh",
        "outputId": "dac11c64-579f-4fd3-93e9-7bf58279693a"
      },
      "source": [
        "print('Classification Report:')\n",
        "print(classification_report(y_true, y_pred, labels=[1,0], digits=4))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8905    0.9020    0.8962     24698\n",
            "           0     0.9018    0.8903    0.8960     24966\n",
            "\n",
            "    accuracy                         0.8961     49664\n",
            "   macro avg     0.8962    0.8962    0.8961     49664\n",
            "weighted avg     0.8962    0.8961    0.8961     49664\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtzH0-7Voh0M"
      },
      "source": [
        "## Own manual classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvJ4uiaYog6s"
      },
      "source": [
        "def f_score(gold, predicted):\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "    d = {}\n",
        "    cm=confusion_matrix(gold,predicted)\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "    FN = cm.sum(axis=1) - np.diag(cm)\n",
        "    TP = np.diag(cm)\n",
        "    TN = cm.sum() - (FP + FN + TP)\n",
        "\n",
        "    # Sensitivity, hit rate, recall, or true positive rate\n",
        "    TPR = TP/(TP+FN)\n",
        "    # Specificity or true negative rate\n",
        "    TNR = TN/(TN+FP) \n",
        "    # Precision or positive predictive value\n",
        "    PPV = TP/(TP+FP)\n",
        "    # Negative predictive value\n",
        "    NPV = TN/(TN+FN)\n",
        "    # Fall out or false positive rate\n",
        "    FPR = FP/(FP+TN)\n",
        "    # False negative rate\n",
        "    FNR = FN/(TP+FN)\n",
        "    # False discovery rate\n",
        "    FDR = FP/(TP+FP)\n",
        "\n",
        "    # Overall accuracy\n",
        "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "    # F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "    f = (2 * PPV * TPR) / (PPV + TPR)\n",
        "    #print(TP, FP, FN)\n",
        "    #print(TPR, PPV)\n",
        "    micro = precision_recall_fscore_support(gold, predicted, average='micro')\n",
        "    macro = precision_recall_fscore_support(gold, predicted, average='macro')\n",
        "    for i in range(2):\n",
        "      #print(i)\n",
        "      d[i]= {'tp':TP[i], 'fp':FP[i], 'fn':FN[i], 'precision': PPV[i], 'recall': TPR[i], 'f': f[i]}\n",
        "    \n",
        "    d['MICRO AVG'] = {'precision': micro[0], 'recall': micro[1], 'f': micro[2]}\n",
        "    d['MACRO AVG'] = {'precision': macro[0], 'recall': macro[1], 'f': macro[2]}\n",
        "\n",
        "    return d"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwxE1QIozHD",
        "outputId": "8bedd2b6-802a-4c6a-bd44-a31d08f7b288"
      },
      "source": [
        "f_score(y_true, y_pred)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'f': 0.8960151573176386,\n",
              "  'fn': 2739,\n",
              "  'fp': 2420,\n",
              "  'precision': 0.9018136081470361,\n",
              "  'recall': 0.8902907954818553,\n",
              "  'tp': 22227},\n",
              " 1: {'f': 0.8962285024640451,\n",
              "  'fn': 2420,\n",
              "  'fp': 2739,\n",
              "  'precision': 0.8905144501738818,\n",
              "  'recall': 0.9020163575998057,\n",
              "  'tp': 22278},\n",
              " 'MACRO AVG': {'f': 0.8961218298908418,\n",
              "  'precision': 0.8961640291604589,\n",
              "  'recall': 0.8961535765408305},\n",
              " 'MICRO AVG': {'f': 0.8961219394329897,\n",
              "  'precision': 0.8961219394329897,\n",
              "  'recall': 0.8961219394329897}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK6nNGo-paTP"
      },
      "source": [
        "# Extra: trying a Machine Learning model\n",
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHZoTUwqqwui",
        "outputId": "c8cd6cfe-2210-4781-9f43-fc2f6cd67313"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   187,  6088,   156],\n",
              "       [    0,     0,     0, ..., 11687, 33563,     3],\n",
              "       [    0,     0,     0, ...,  1019,  3085,   623],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,  7010,  7102,   149],\n",
              "       [    0,     0,     0, ...,     8,   578,   492],\n",
              "       [    0,     0,     0, ...,    21,   655, 84590]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGKC_Kjopcmj",
        "outputId": "9763a7a2-46f6-4565-ffcd-9931fb1bcb91"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from wordcloud import STOPWORDS\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "stopwords = set(STOPWORDS)\n",
        "stopwords.remove(\"not\")\n",
        "\n",
        "\n",
        "# df_balanced.cleaned_text\n",
        "\n",
        "split = df_balanced[[\"cleaned_text\" , \"target\"]]\n",
        "train_nb =split.sample(frac=0.8,random_state=1)\n",
        "test_nb =split.drop(train_nb.index)\n",
        "\n",
        "count_vect = CountVectorizer(min_df=2 ,stop_words=stopwords , ngram_range=(1,2))\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(train_nb[\"cleaned_text\"])        \n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "\n",
        "X_new_counts = count_vect.transform(test_nb[\"cleaned_text\"])\n",
        "X_test_tfidf = tfidf_transformer.transform(X_new_counts)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYlYUmQQsZIO",
        "outputId": "36584203-4da6-4efc-f9ad-88564463cc63"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "prediction =  {}\n",
        "model1 = MultinomialNB().fit(X_train_tfidf , train_nb[\"target\"])\n",
        "prediction['Multinomial'] = model1.predict_proba(X_test_tfidf)[:,1]\n",
        "print(\"Multinomial Accuracy : {}\".format(model1.score(X_test_tfidf , test_nb[\"target\"])))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial Accuracy : 0.8792678634283703\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}